{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "from mxnet import np, npx\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import nn\n",
    "import mxnet.gluon.probability as mgp\n",
    "from mxnet.gluon.probability import StochasticBlock, StochasticSequential\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "npx.set_np()\n",
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_logistic_data(num_examples, input_size=2, weights_prior_stddev=5.0):\n",
    "    \"\"\"Generates synthetic data for binary classification.\n",
    "    Args:\n",
    "    num_examples: The number of samples to generate (scalar Python `int`).\n",
    "    input_size: The input space dimension (scalar Python `int`).\n",
    "    weights_prior_stddev: The prior standard deviation of the weight\n",
    "        vector. (scalar Python `float`).\n",
    "    Returns:\n",
    "    random_weights: Sampled weights as a Numpy `array` of shape\n",
    "        `[input_size]`.\n",
    "    random_bias: Sampled bias as a scalar Python `float`.\n",
    "    design_matrix: Points sampled uniformly from the cube `[-1,\n",
    "        1]^{input_size}`, as a Numpy `array` of shape `(num_examples,\n",
    "        input_size)`.\n",
    "    labels: Labels sampled from the logistic model `p(label=1) =\n",
    "        logistic(dot(features, random_weights) + random_bias)`, as a Numpy\n",
    "        `int32` `array` of shape `(num_examples, 1)`.\n",
    "    \"\"\"\n",
    "    random_weights = weights_prior_stddev * np.random.randn(input_size)\n",
    "    random_bias = np.random.randn()\n",
    "    design_matrix = np.random.rand(num_examples, input_size) * 2 - 1\n",
    "    logits = np.reshape(\n",
    "      np.dot(design_matrix, random_weights) + random_bias,\n",
    "      (-1, 1))\n",
    "    p_labels = 1. / (1 + np.exp(-logits))\n",
    "    labels = np.int32(p_labels > np.random.rand(num_examples, 1))\n",
    "    return random_weights, random_bias, np.float32(design_matrix), labels\n",
    "\n",
    "\n",
    "def load_data(batch_size):\n",
    "    \"\"\"\n",
    "    Load MNIST\n",
    "    \"\"\"\n",
    "    mnist_train = gluon.data.vision.MNIST(train=True)\n",
    "    mnist_test = gluon.data.vision.MNIST(train=False)\n",
    "    num_worker = 4\n",
    "    transformer = gluon.data.vision.transforms.ToTensor()\n",
    "    return (gluon.data.DataLoader(mnist_train.transform_first(transformer),\n",
    "                                batch_size, shuffle=True,\n",
    "                                num_workers=num_worker),\n",
    "          gluon.data.DataLoader(mnist_test.transform_first(transformer),\n",
    "                                batch_size, shuffle=False,\n",
    "                                num_workers=num_worker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct A Bayesian dense layer using local reparameterization trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalReparamDense(StochasticBlock):\n",
    "    def __init__(self, in_features, out_features, activation=None, flatten=True, dtype='float32'):\n",
    "        super(LocalReparamDense, self).__init__()\n",
    "        self._flatten = flatten\n",
    "        self.qw_x = None\n",
    "        with self.name_scope():\n",
    "            self._in_features = in_features\n",
    "            self._out_features = out_features\n",
    "            # Parameter of weight\n",
    "            self.loc_w = self.params.get('loc_w', shape=(out_features, in_features),\n",
    "                                        dtype=dtype)\n",
    "            self.scale_w = self.params.get('scale_w', shape=(out_features, in_features),\n",
    "                                        dtype=dtype)\n",
    "            # Parameter of bias\n",
    "            self.bias = self.params.get('bias', shape=(out_features,),\n",
    "                                        dtype=dtype)\n",
    "            if activation is not None:\n",
    "                self.act = gluon.nn.Activation(activation, prefix=activation + '_')\n",
    "            else:\n",
    "                self.act = None\n",
    "\n",
    "    @StochasticBlock.collectLoss\n",
    "    def hybrid_forward(self, F, x, loc_w, scale_w, bias):\n",
    "        # We use `fc` operator for matrix multiplication.\n",
    "        fc = F.npx.fully_connected\n",
    "        # Directly acquire parameter for A = dot(x, W)\n",
    "        # with local reparameterization trick:\n",
    "        qa_loc = fc(x, loc_w, bias=None, no_bias=True, num_hidden=self._out_features,\n",
    "                    flatten=self._flatten)\n",
    "        qa_scale = F.np.sqrt(fc(x ** 2, scale_w ** 2, bias=None, no_bias=True,\n",
    "                      num_hidden=self._out_features, flatten=self._flatten))\n",
    "        self.qw_x = mgp.Normal(\n",
    "            loc=qa_loc,\n",
    "            scale=qa_scale\n",
    "        )\n",
    "        # KL(qw_x || px), where px ~ N(0, 1)\n",
    "        kl = mgp.kl_divergence(self.qw_x, mgp.Normal(0, 1)).sum(-1)\n",
    "        self.add_loss(kl)\n",
    "        # Sampling from the network\n",
    "        fc_samples = self.qw_x.sample() + bias\n",
    "        if self.act is not None:\n",
    "            out = self.act(fc_samples)\n",
    "        else:\n",
    "            out = fc_samples\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classfication with BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, n_epoch, train_iter, test_iter, baseline=False):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam',\n",
    "                      {'learning_rate': .001})\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    loss_func = gluon.loss.SoftmaxCrossEntropyLoss(from_logits=(not baseline))\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for epoch in tqdm_notebook(range(n_epoch), desc='epochs'):\n",
    "        epoch_loss = 0\n",
    "        metric.reset()\n",
    "        for batch in train_iter:\n",
    "            data = batch[0].as_in_context(model_ctx).reshape(-1, 28 * 28)\n",
    "            label = batch[1].as_in_context(model_ctx)\n",
    "            kl_loss = 0\n",
    "            with autograd.record():\n",
    "                logits = net(data)\n",
    "                classification_loss = loss_func(logits, label)\n",
    "                # `baseline` model stands for deterministic MLP\n",
    "                if baseline:\n",
    "                    loss = classification_loss\n",
    "                else:\n",
    "                    for layer_kl_loss in net.losses:\n",
    "                        kl_loss = kl_loss + layer_kl_loss[0]\n",
    "                    loss = classification_loss + kl_loss / 256\n",
    "            loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "            epoch_loss += np.mean(loss)\n",
    "        test_loss = 0\n",
    "        for batch in test_iter:\n",
    "            data = batch[0].as_in_context(model_ctx).reshape(-1, 28 * 28)\n",
    "            label = batch[1].as_in_context(model_ctx)\n",
    "            logits = net(data)\n",
    "            classification_loss = loss_func(logits, label)\n",
    "            test_loss += np.mean(classification_loss)\n",
    "            metric.update([label], [logits.as_nd_ndarray()])\n",
    "        name, acc = metric.get()\n",
    "        print('[Epoch %d] Training: %s=%f'%(epoch, name, acc))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.HybridSequential()\n",
    "mlp.add(nn.Dense(256, activation='relu'))\n",
    "mlp.add(nn.Dense(256, activation='relu'))\n",
    "mlp.add(nn.Dense(10))\n",
    "mlp.collect_params().initialize(ctx=model_ctx)\n",
    "mlp.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn = StochasticSequential()\n",
    "bnn.add(LocalReparamDense(784, 256, activation='relu'))\n",
    "bnn.add(LocalReparamDense(256, 256, activation='relu'))\n",
    "bnn.add(LocalReparamDense(256, 10))\n",
    "bnn.collect_params().initialize(ctx=model_ctx)\n",
    "bnn.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca1dd19ca7840d6a2a5e92f79cabb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epochs', max=50.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Training: accuracy=0.947200\n",
      "[Epoch 1] Training: accuracy=0.965500\n",
      "[Epoch 2] Training: accuracy=0.971700\n",
      "[Epoch 3] Training: accuracy=0.974100\n",
      "[Epoch 4] Training: accuracy=0.977400\n",
      "[Epoch 5] Training: accuracy=0.977900\n",
      "[Epoch 6] Training: accuracy=0.979500\n",
      "[Epoch 7] Training: accuracy=0.979000\n",
      "[Epoch 8] Training: accuracy=0.978500\n",
      "[Epoch 9] Training: accuracy=0.980100\n",
      "[Epoch 10] Training: accuracy=0.980200\n",
      "[Epoch 11] Training: accuracy=0.980700\n",
      "[Epoch 12] Training: accuracy=0.980900\n",
      "[Epoch 13] Training: accuracy=0.979300\n",
      "[Epoch 14] Training: accuracy=0.979400\n",
      "[Epoch 15] Training: accuracy=0.980200\n",
      "[Epoch 16] Training: accuracy=0.980300\n",
      "[Epoch 17] Training: accuracy=0.979500\n",
      "[Epoch 18] Training: accuracy=0.978100\n",
      "[Epoch 19] Training: accuracy=0.979300\n",
      "[Epoch 20] Training: accuracy=0.980500\n",
      "[Epoch 21] Training: accuracy=0.980300\n",
      "[Epoch 22] Training: accuracy=0.982500\n",
      "[Epoch 23] Training: accuracy=0.981400\n",
      "[Epoch 24] Training: accuracy=0.979900\n",
      "[Epoch 25] Training: accuracy=0.975200\n",
      "[Epoch 26] Training: accuracy=0.978700\n",
      "[Epoch 27] Training: accuracy=0.981700\n",
      "[Epoch 28] Training: accuracy=0.977800\n",
      "[Epoch 29] Training: accuracy=0.981800\n",
      "[Epoch 30] Training: accuracy=0.982800\n",
      "[Epoch 31] Training: accuracy=0.979700\n",
      "[Epoch 32] Training: accuracy=0.980400\n",
      "[Epoch 33] Training: accuracy=0.980500\n",
      "[Epoch 34] Training: accuracy=0.978500\n",
      "[Epoch 35] Training: accuracy=0.980600\n",
      "[Epoch 36] Training: accuracy=0.982100\n",
      "[Epoch 37] Training: accuracy=0.981500\n",
      "[Epoch 38] Training: accuracy=0.983800\n",
      "[Epoch 39] Training: accuracy=0.984000\n",
      "[Epoch 40] Training: accuracy=0.984100\n",
      "[Epoch 41] Training: accuracy=0.984300\n",
      "[Epoch 42] Training: accuracy=0.984200\n",
      "[Epoch 43] Training: accuracy=0.984300\n",
      "[Epoch 44] Training: accuracy=0.984300\n",
      "[Epoch 45] Training: accuracy=0.984300\n",
      "[Epoch 46] Training: accuracy=0.984500\n",
      "[Epoch 47] Training: accuracy=0.984400\n",
      "[Epoch 48] Training: accuracy=0.984500\n",
      "[Epoch 49] Training: accuracy=0.984500\n",
      "\n",
      "CPU times: user 1min 3s, sys: 14.5 s, total: 1min 18s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 256\n",
    "train_set, test_set = load_data(batch_size)\n",
    "train(mlp, 50, train_set, test_set, baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52a2a03347e4a22ae1c66cb4b3077f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epochs', max=50.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Training: accuracy=0.913800\n",
      "[Epoch 1] Training: accuracy=0.949400\n",
      "[Epoch 2] Training: accuracy=0.961700\n",
      "[Epoch 3] Training: accuracy=0.968000\n",
      "[Epoch 4] Training: accuracy=0.972100\n",
      "[Epoch 5] Training: accuracy=0.971600\n",
      "[Epoch 6] Training: accuracy=0.975100\n",
      "[Epoch 7] Training: accuracy=0.976400\n",
      "[Epoch 8] Training: accuracy=0.975400\n",
      "[Epoch 9] Training: accuracy=0.977600\n",
      "[Epoch 10] Training: accuracy=0.978100\n",
      "[Epoch 11] Training: accuracy=0.977800\n",
      "[Epoch 12] Training: accuracy=0.977900\n",
      "[Epoch 13] Training: accuracy=0.979400\n",
      "[Epoch 14] Training: accuracy=0.978900\n",
      "[Epoch 15] Training: accuracy=0.978600\n",
      "[Epoch 16] Training: accuracy=0.980200\n",
      "[Epoch 17] Training: accuracy=0.979800\n",
      "[Epoch 18] Training: accuracy=0.979700\n",
      "[Epoch 19] Training: accuracy=0.980700\n",
      "[Epoch 20] Training: accuracy=0.980100\n",
      "[Epoch 21] Training: accuracy=0.979600\n",
      "[Epoch 22] Training: accuracy=0.980500\n",
      "[Epoch 23] Training: accuracy=0.979000\n",
      "[Epoch 24] Training: accuracy=0.979500\n",
      "[Epoch 25] Training: accuracy=0.980400\n",
      "[Epoch 26] Training: accuracy=0.980600\n",
      "[Epoch 27] Training: accuracy=0.979600\n",
      "[Epoch 28] Training: accuracy=0.980500\n",
      "[Epoch 29] Training: accuracy=0.979700\n",
      "[Epoch 30] Training: accuracy=0.979000\n",
      "[Epoch 31] Training: accuracy=0.980600\n",
      "[Epoch 32] Training: accuracy=0.979900\n",
      "[Epoch 33] Training: accuracy=0.980500\n",
      "[Epoch 34] Training: accuracy=0.978600\n",
      "[Epoch 35] Training: accuracy=0.978400\n",
      "[Epoch 36] Training: accuracy=0.978500\n",
      "[Epoch 37] Training: accuracy=0.978800\n",
      "[Epoch 38] Training: accuracy=0.979200\n",
      "[Epoch 39] Training: accuracy=0.978900\n",
      "[Epoch 40] Training: accuracy=0.979200\n",
      "[Epoch 41] Training: accuracy=0.978800\n",
      "[Epoch 42] Training: accuracy=0.979100\n",
      "[Epoch 43] Training: accuracy=0.977900\n",
      "[Epoch 44] Training: accuracy=0.978400\n",
      "[Epoch 45] Training: accuracy=0.979200\n",
      "[Epoch 46] Training: accuracy=0.977800\n",
      "[Epoch 47] Training: accuracy=0.976700\n",
      "[Epoch 48] Training: accuracy=0.978300\n",
      "[Epoch 49] Training: accuracy=0.978300\n",
      "\n",
      "CPU times: user 1min 43s, sys: 14.5 s, total: 1min 58s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 256\n",
    "train_set, test_set = load_data(batch_size)\n",
    "train(bnn, 50, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572b4e1c05a246a085f5bb5fa86b21df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epochs', max=50.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Training: accuracy=0.915500\n",
      "[Epoch 1] Training: accuracy=0.947000\n",
      "[Epoch 2] Training: accuracy=0.959000\n",
      "[Epoch 3] Training: accuracy=0.966700\n",
      "[Epoch 4] Training: accuracy=0.970200\n",
      "[Epoch 5] Training: accuracy=0.973900\n",
      "[Epoch 6] Training: accuracy=0.973800\n",
      "[Epoch 7] Training: accuracy=0.975300\n",
      "[Epoch 8] Training: accuracy=0.976300\n",
      "[Epoch 9] Training: accuracy=0.976700\n",
      "[Epoch 10] Training: accuracy=0.977900\n",
      "[Epoch 11] Training: accuracy=0.978600\n",
      "[Epoch 12] Training: accuracy=0.979500\n",
      "[Epoch 13] Training: accuracy=0.978800\n",
      "[Epoch 14] Training: accuracy=0.978500\n",
      "[Epoch 15] Training: accuracy=0.980900\n",
      "[Epoch 16] Training: accuracy=0.980700\n",
      "[Epoch 17] Training: accuracy=0.979300\n",
      "[Epoch 18] Training: accuracy=0.980800\n",
      "[Epoch 19] Training: accuracy=0.980600\n",
      "[Epoch 20] Training: accuracy=0.980600\n",
      "[Epoch 21] Training: accuracy=0.978800\n",
      "[Epoch 22] Training: accuracy=0.980200\n",
      "[Epoch 23] Training: accuracy=0.981700\n",
      "[Epoch 24] Training: accuracy=0.979600\n",
      "[Epoch 25] Training: accuracy=0.979300\n",
      "[Epoch 26] Training: accuracy=0.980600\n",
      "[Epoch 27] Training: accuracy=0.980800\n",
      "[Epoch 28] Training: accuracy=0.980400\n",
      "[Epoch 29] Training: accuracy=0.980700\n",
      "[Epoch 30] Training: accuracy=0.978800\n",
      "[Epoch 31] Training: accuracy=0.978600\n",
      "[Epoch 32] Training: accuracy=0.979400\n",
      "[Epoch 33] Training: accuracy=0.977700\n",
      "[Epoch 34] Training: accuracy=0.979300\n",
      "[Epoch 35] Training: accuracy=0.978600\n",
      "[Epoch 36] Training: accuracy=0.978800\n",
      "[Epoch 37] Training: accuracy=0.980100\n",
      "[Epoch 38] Training: accuracy=0.979900\n",
      "[Epoch 39] Training: accuracy=0.979500\n",
      "[Epoch 40] Training: accuracy=0.980900\n",
      "[Epoch 41] Training: accuracy=0.978500\n",
      "[Epoch 42] Training: accuracy=0.979500\n",
      "[Epoch 43] Training: accuracy=0.979500\n",
      "[Epoch 44] Training: accuracy=0.979700\n",
      "[Epoch 45] Training: accuracy=0.978300\n",
      "[Epoch 46] Training: accuracy=0.979800\n",
      "[Epoch 47] Training: accuracy=0.978900\n",
      "[Epoch 48] Training: accuracy=0.979200\n",
      "[Epoch 49] Training: accuracy=0.979400\n",
      "\n",
      "CPU times: user 3min 6s, sys: 23.5 s, total: 3min 30s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 256\n",
    "train_set, test_set = load_data(batch_size)\n",
    "train(bnn, 50, train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform classfication on white noise to demonstrate the advantages of a Bayesian neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0fc9dd3748>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate random noise\n",
    "x = np.random.randn(28, 28)\n",
    "plt.imshow(x.asnumpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "bnn_prediction = npx.softmax(bnn(np.repeat(np.expand_dims(x, 0), 100, 0).as_in_context(model_ctx))).mean(0).asnumpy()\n",
    "mlp_prediction = npx.softmax(mlp(np.repeat(np.expand_dims(x, 0), 100, 0).as_in_context(model_ctx))).mean(0).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0fc9c73c50>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [str(i) for i in range(10)]\n",
    "x = np.arange(len(labels)).asnumpy()  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, bnn_prediction, width, label='BNN prediction')\n",
    "rects2 = ax.bar(x + width/2, mlp_prediction, width, label='MLP prediction')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
